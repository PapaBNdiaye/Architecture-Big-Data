#!/usr/bin/env python3
"""
Script de test pour valider la configuration de l'architecture Lambda batch
"""

import os
import sys
import requests
import subprocess
import time
from typing import Dict, List, Tuple

class BatchSetupTester:
    def __init__(self):
        self.test_results = {}
        self.services_to_test = {
            'hdfs-namenode': 'http://localhost:9870',
            'spark-master': 'http://localhost:9090', 
            'airflow': 'http://localhost:8080',
            'kafka': 'http://localhost:9021'
        }
    
    def test_environment_variables(self) -> bool:
        """Teste les variables d'environnement requises"""
        print("üß™ Test des variables d'environnement...")
        
        required_vars = ['VISUAL_CROSSING_API_KEY']
        missing_vars = []
        
        for var in required_vars:
            value = os.getenv(var)
            if not value or value == 'VOTRE_API_KEY':
                missing_vars.append(var)
                print(f"  ‚ùå {var}: Non configur√©e")
            else:
                print(f"  ‚úÖ {var}: Configur√©e")
        
        if missing_vars:
            print(f"‚ö†Ô∏è  Variables manquantes: {', '.join(missing_vars)}")
            return False
        
        print("‚úÖ Toutes les variables d'environnement sont configur√©es")
        return True
    
    def test_docker_services(self) -> bool:
        """Teste la disponibilit√© des services Docker"""
        print("\nüß™ Test des services Docker...")
        
        try:
            # V√©rification que docker-compose est disponible
            result = subprocess.run(['docker-compose', 'ps'], 
                                  capture_output=True, text=True, timeout=10)
            
            if result.returncode != 0:
                print("‚ùå Docker Compose non disponible")
                return False
            
            # Analyse des services en cours d'ex√©cution
            services_running = []
            for line in result.stdout.split('\n'):
                if 'Up' in line:
                    service_name = line.split()[0]
                    services_running.append(service_name)
            
            # V√©rification des services essentiels (noms r√©els des conteneurs)
            essential_services = ['hdfs-namenode', 'spark-master', 'webserver']
            found_services = []
            
            for service in essential_services:
                if any(service in s for s in services_running):
                    found_services.append(service)
            
            missing_services = [s for s in essential_services if s not in found_services]
            
            if missing_services:
                print(f"‚ùå Services manquants: {', '.join(missing_services)}")
                return False
            
            print(f"‚úÖ Services Docker en cours d'ex√©cution: {', '.join(services_running)}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors du test Docker: {e}")
            return False
    
    def test_service_connectivity(self) -> Dict[str, bool]:
        """Teste la connectivit√© aux services"""
        print("\nüß™ Test de connectivit√© aux services...")
        
        results = {}
        
        for service, url in self.services_to_test.items():
            try:
                response = requests.get(url, timeout=10)
                is_accessible = response.status_code == 200
                results[service] = is_accessible
                
                status = "‚úÖ" if is_accessible else "‚ùå"
                print(f"  {status} {service}: {url} (HTTP {response.status_code})")
                
            except requests.exceptions.RequestException as e:
                results[service] = False
                print(f"  ‚ùå {service}: {url} (Erreur: {e})")
        
        return results
    
    def test_hdfs_functionality(self) -> bool:
        """Teste la fonctionnalit√© HDFS"""
        print("\nüß™ Test de la fonctionnalit√© HDFS...")
        
        try:
            # Test de cr√©ation d'un r√©pertoire
            test_dir = "/test_batch_setup"
            create_cmd = f"docker exec hdfs-namenode hdfs dfs -mkdir -p {test_dir}"
            result = subprocess.run(create_cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode != 0:
                print(f"‚ùå Impossible de cr√©er le r√©pertoire HDFS: {result.stderr}")
                return False
            
            # Test de liste des r√©pertoires
            list_cmd = "docker exec hdfs-namenode hdfs dfs -ls /"
            result = subprocess.run(list_cmd, shell=True, capture_output=True, text=True)
            
            if result.returncode != 0:
                print(f"‚ùå Impossible de lister les r√©pertoires HDFS: {result.stderr}")
                return False
            
            # Test de suppression du r√©pertoire de test
            delete_cmd = f"docker exec hdfs-namenode hdfs dfs -rm -r {test_dir}"
            subprocess.run(delete_cmd, shell=True, capture_output=True, text=True)
            
            print("‚úÖ HDFS fonctionne correctement")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors du test HDFS: {e}")
            return False
    
    def test_spark_functionality(self) -> bool:
        """Teste la fonctionnalit√© Spark"""
        print("\nüß™ Test de la fonctionnalit√© Spark...")
        
        try:
            # Test simple de connectivit√© Spark Master (rapide)
            response = requests.get('http://localhost:9090', timeout=5)
            if response.status_code == 200:
                print("‚úÖ Spark Master accessible")
                return True
            else:
                print(f"‚ùå Spark Master non accessible: HTTP {response.status_code}")
                return False
                
        except Exception as e:
            print(f"‚ùå Erreur lors du test Spark: {e}")
            return False
    
    def test_batch_processing_import(self) -> bool:
        """Teste l'importation du module batch_processing"""
        print("\nüß™ Test d'importation du module batch_processing...")
        
        try:
            # Ajout du r√©pertoire courant au path
            sys.path.insert(0, os.getcwd())
            
            # Import du module
            from batch_processing import WeatherBatchProcessor
            
            # Test d'instanciation
            processor = WeatherBatchProcessor(api_key="test_key")
            
            print("‚úÖ Module batch_processing import√© avec succ√®s")
            return True
            
        except ImportError as e:
            print(f"‚ùå Erreur d'importation: {e}")
            return False
        except Exception as e:
            print(f"‚ùå Erreur lors de l'instanciation: {e}")
            return False
    
    def test_airflow_dag_syntax(self) -> bool:
        """Teste la syntaxe du DAG Airflow"""
        print("\nüß™ Test de la syntaxe du DAG Airflow...")
        
        try:
            dag_file = "dags/weather_batch_dag.py"
            
            if not os.path.exists(dag_file):
                print(f"‚ùå Fichier DAG non trouv√©: {dag_file}")
                return False
            
            # Test de compilation Python
            with open(dag_file, 'r') as f:
                code = f.read()
            
            compile(code, dag_file, 'exec')
            print("‚úÖ Syntaxe du DAG Airflow valide")
            return True
            
        except SyntaxError as e:
            print(f"‚ùå Erreur de syntaxe dans le DAG: {e}")
            return False
        except Exception as e:
            print(f"‚ùå Erreur lors du test du DAG: {e}")
            return False
    
    def run_all_tests(self) -> Dict[str, bool]:
        """Ex√©cute tous les tests"""
        print("üöÄ D√©but des tests de configuration batch\n")
        
        tests = [
            ("Variables d'environnement", self.test_environment_variables),
            ("Services Docker", self.test_docker_services),
            ("Connectivit√© services", lambda: all(self.test_service_connectivity().values())),
            ("Fonctionnalit√© HDFS", self.test_hdfs_functionality),
            ("Fonctionnalit√© Spark", self.test_spark_functionality),
            ("Import batch_processing", self.test_batch_processing_import),
            ("Syntaxe DAG Airflow", self.test_airflow_dag_syntax)
        ]
        
        results = {}
        
        for test_name, test_func in tests:
            try:
                result = test_func()
                results[test_name] = result
            except Exception as e:
                print(f"‚ùå Erreur lors du test '{test_name}': {e}")
                results[test_name] = False
        
        return results
    
    def print_summary(self, results: Dict[str, bool]):
        """Affiche le r√©sum√© des tests"""
        print("\n" + "="*50)
        print("üìä R√âSUM√â DES TESTS")
        print("="*50)
        
        passed = sum(results.values())
        total = len(results)
        
        for test_name, result in results.items():
            status = "‚úÖ PASS√â" if result else "‚ùå √âCHOU√â"
            print(f"{status} {test_name}")
        
        print(f"\nR√©sultat global: {passed}/{total} tests r√©ussis")
        
        if passed == total:
            print("\nüéâ Tous les tests sont pass√©s ! L'architecture batch est pr√™te.")
        else:
            print(f"\n‚ö†Ô∏è  {total - passed} test(s) ont √©chou√©. V√©rifiez la configuration.")
            
            # Suggestions de d√©pannage
            print("\nüîß Suggestions de d√©pannage:")
            for test_name, result in results.items():
                if not result:
                    if "Variables" in test_name:
                        print("  - Configurez la variable VISUAL_CROSSING_API_KEY")
                    elif "Docker" in test_name:
                        print("  - Ex√©cutez: docker-compose up -d")
                    elif "Connectivit√©" in test_name:
                        print("  - Attendez que tous les services soient d√©marr√©s (2-3 minutes)")
                    elif "HDFS" in test_name:
                        print("  - V√©rifiez les logs: docker-compose logs hdfs-namenode")
                    elif "Spark" in test_name:
                        print("  - V√©rifiez les logs: docker-compose logs spark-master")

def main():
    """Fonction principale"""
    tester = BatchSetupTester()
    results = tester.run_all_tests()
    tester.print_summary(results)
    
    # Code de sortie bas√© sur les r√©sultats
    if all(results.values()):
        sys.exit(0)  # Succ√®s
    else:
        sys.exit(1)  # √âchec

if __name__ == "__main__":
    main()
